<html>
<head>
	<title>Evan Z. Liu</title>
	<link rel="stylesheet" href="stylesheet.css"/>
	<link href='https://fonts.googleapis.com/css?family=Sorts+Mill+Goudy' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Josefin+Slab:300' rel='stylesheet' type='text/css'>
</head>
<body>
  <div id="container">
    <div id="header">
      <h2 id="me" class="goudy">
        <div>Evan Z. Liu</div>
        <div style="font-size: 18; font-weight: normal">
          Stanford CS PhD Student
        </div>
      </h2>

      <ul id="nav" class="goudy">
        <!--<li>
          <a href="#about" class="button">About</a>
        </li>
        <li>
          <a href="#publications" class="button">Publications</a>
        </li>
        <li>
          <a href="#contact" class="button">Contact</a>
        </li>-->
        <li>
          <a href="https://scholar.google.com/citations?user=qjDVoqQAAAAJ&hl=en" class="button">Google Scholar</a>
        </li>
        <li>
          <a href="resume.pdf" class="button">Resume</a>
        </li>
      </ul>
    </div>

    <hr>

    <div id="about">
      <h2 class="goudy">About</h2>
      <img src="images/evan.jpg">
      <p>
        Hi! I'm a second-year CS PhD student studying machine learning at
        Stanford University, advised by
        <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>.
        My research is funded by a
        <a href="https://www.nsfgrfp.org/">National Science Foundation Graduate Fellowship</a>.
        I also spend one day a week applying machine learning to systems problems at Google Research.
        Previously, I spent a year as a
        <a href="https://ai.google/research/join-us/ai-residency/">Google AI resident</a>
        and before that, completed my
        master's (CS) and my undergraduate degrees (CS and math) at Stanford,
        advised by <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>.
      </p>

      <p>
        My goal is to build intelligent agents that can practically help humans.
        Toward this end, I work on <i>meta-reinforcement learning</i> to ensure that agents can quickly adapt to new environments and tasks.
        For example, we might want a robot chef that can quickly adapt to a home kitchen after training inside a factory.
        In past research, I've examined the meta-exploration problem, where the agent must gather information in its new environment (e.g., find the ingredients in a new kitchen) in order to adapt (<a href="https://arxiv.org/abs/2008.02790">ArXiv 2020</a>).
      </p>

      <p>
        I also work toward this goal by applying machine learning to computer
        systems, where data is plentiful and advances can quickly yield
        tangible real-world impact.
        Here, I aim to replace <i>handcrafted</i> heuristics with
        <i>learned</i> models, which can significantly improve performance,
        e.g., in cache replacement
        (<a href="https://arxiv.org/abs/2006.16239">ICML 2020</a>).
        Of course, directly deploying these learned models requires
        solving additional challenges (e.g., minimizing model latency and size),
        but in the meantime, these models can still improve existing systems
        (e.g., by yielding insights that can be incorporated through more
        traditional avenues).
        I am also fascinated by computer security and would love to apply
        reinforcement learning ideas to automatically detecting
        vulnerabilities.
      </p>

      <p>
        I love rock climbing and spend most of my free time bouldering indoors,
        although I'm hoping to climb more outside in the future.
        I'm always on the lookout for more climbing friends, so let me know if
        you like to climb or want to try it out!
      </p>
    </div>

    <hr>

    <div id="publications" class="goudy">
      <h2 class="goudy">Publications</h2>
      <ul id="paper_list">
        <li>
          <div class="paper">
            Explore then Execute: Adapting without Rewards via Factorized Meta-Reinforcement Learning
          </div>
          <div class="paper_details">
            <b>Evan Zheran Liu</b>, <a href="https://stanford.edu/~aditir/">Aditi Raghunathan</a>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>, <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
            <br>
            <i>LifeLong ML Workshop (ICML), 2020</i>
            <br>
            <div class="tags" style="width: 50%">
              <a href="https://arxiv.org/abs/2008.02790">[paper]</a>
              <a href="https://youtu.be/EiIC0Rkz8-s">[short talk]</a>
              <a href="https://ezliu.github.io/dream">[website]</a>
              <a href="https://github.com/ezliu/dream">[code]</a>
            </div>
          </div>
        </li>

        <li>
          <div class="paper">
            An Imitation Learning Approach for Cache Replacement
          </div>
          <div class="paper_details">
            <b>Evan Zheran Liu</b>, <a href="https://research.google/people/MiladHashemi/">Milad Hashemi</a>, <a href="https://research.google/people/105739/">Kevin Swersky</a>, <a href="https://research.google/people/ParthasarathyRanganathan/">Parthasarathy Ranganathan</a>, <a href="https://research.google/people/JunwhanAhn/">Junwhan Ahn</a>
            <br>
            <i>International Conference on Machine Learning (ICML), 2020</i>
            <br>
            <div class="tags" style="width: 20%">
              <a href="https://arxiv.org/abs/2006.16239">[paper]</a>
              <a href="https://github.com/google-research/google-research/tree/master/cache_replacement">[code]</a>
            </div>
          </div>
        </li>

        <li>
          <div class="paper">
            Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration
          </div>
          <div class="paper_details">
            <b>Evan Zheran Liu</b>*, <a href="https://www.kelvinguu.com/">Kelvin Guu</a>*, <a href="https://ppasupat.github.io/">Panupong Pasupat</a>*, <a href="https://www.linkedin.com/in/tianlinshi/">Tianlin Shi</a>, <a href="https://www.linkedin.com/in/tianlinshi/">Percy Liang</a>
            <br>
            (*) denotes equal contribution
            <br>
            <i>International Conference on Learning Representations (ICLR), 2018</i>
            <br>
            <div class="tags">
              <a href="https://arxiv.org/abs/1802.08802">[paper]</a>
              <a href="https://github.com/stanfordnlp/wge">[code]</a>
            </div>
          </div>
        </li>

        <li>
          <div class="paper">
            Mapping Natural Language Commands to Web Elements
          </div>
          <div class="paper_details">
            <a href="https://ppasupat.github.io/">Panupong Pasupat</a>, <a href="https://www.linkedin.com/in/jiangts/">Tian-Shun Jiang</a>, <b>Evan Zheran Liu</b>, <a href="https://www.kelvinguu.com/">Kelvin Guu</a>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>
            <br>
            <i>Empirical Methods in Natural Language Processing (EMNLP), 2018</i>
            <br>
            <div class="tags">
              <a href="https://arxiv.org/abs/1808.09132">[paper]</a>
              <a href="https://github.com/stanfordnlp/phrasenode">[code]</a>
            </div>
          </div>
        </li>

        <li>
          <div class="paper">
            Learning Abstract Models for Strategic Exploration and Fast Reward Transfer
          </div>
          <div class="paper_details">
            <b>Evan Zheran Liu</b>, <a href="https://rkeramati.github.io/">Ramtin Keramati</a>, <a href="https://www.linkedin.com/in/sudarshanseshadri">Sudarshan Seshadri</a>, <a href="https://www.kelvinguu.com/">Kelvin Guu</a>, <a href="https://ppasupat.github.io/">Panupong Pasupat</a>, <a href="https://cs.stanford.edu/people/ebrun/">Emma Brunskill</a>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>
            <br>
            <i>Workshop on Exploration in Reinforcement Learning (ICML), 2018</i>
            <br>
            <div class="tags">
              <a href="https://arxiv.org/abs/2007.05896">[paper]</a>
              <a href="https://github.com/google-research/google-research/tree/master/strategic_exploration">[code]</a>
            </div>
          </div>
        </li>

        <li>
          <div class="paper">
            From Language to Programs: Bridging Reinforcement Learning and
            Maximum Marginal Likelihood 
          </div>
          <div class="paper_details">
            <a href="https://www.kelvinguu.com/">Kelvin Guu</a>, <a href="https://ppasupat.github.io/">Panupong Pasupat</a>, <b>Evan Zheran Liu</b>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>
            <br>
            <i>Association for Computational Linguistics (ACL), 2017</i>
            <br>
            <div class="tags">
              <a href="https://arxiv.org/abs/1704.07926">[paper]</a>
              <a href="https://github.com/kelvinguu/lang2program">[code]</a>
            </div>
          </div>
        </li>
      </ul>
    </div>

    <hr>

    <div id="contact">
      <h2 class="goudy">Contact</h2>
      <p>You can reach me at [my first name][my last name]@cs.stanford.edu</p>
      <p> Last updated: <b>August 6, 2020</b> </p>
    </div>
  </div>
</body>
</html>
